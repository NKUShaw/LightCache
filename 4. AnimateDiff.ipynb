{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9490c554-ee2b-4dc1-a169-58253fc5214e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lpips\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from diffusers.models.autoencoders.autoencoder_kl import AutoencoderKL, AutoencoderKLOutput\n",
    "from diffusers.models.autoencoders.vae import Decoder, DecoderOutput, DiagonalGaussianDistribution, Encoder\n",
    "from typing import Union, Tuple\n",
    "from diffusers import AnimateDiffPipeline, MotionAdapter, EulerDiscreteScheduler, DDIMScheduler\n",
    "from torchvision.transforms import Resize, ToTensor, Compose\n",
    "from diffusers.utils import export_to_gif, load_image\n",
    "from huggingface_hub import hf_hub_download\n",
    "from safetensors.torch import load_file\n",
    "from LightCache.LightCache import LightCacher\n",
    "from fme import FMEWrapper\n",
    "from time import time\n",
    "from PIL import Image, ImageSequence\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7942b016-e7a0-4a7c-8264-ed5b763961cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frames(frames, size=(256, 256)):\n",
    "    transform = Compose([\n",
    "        Resize(size),\n",
    "        ToTensor(),                     # (C, H, W), range [0,1]\n",
    "        lambda x: x * 2 - 1             # normalize to [-1, 1]\n",
    "    ])\n",
    "    return [transform(f) for f in frames]\n",
    "\n",
    "def compute_lpips(frames1, frames2):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "    scores = []\n",
    "    frames1_tensor = preprocess_frames(frames1, size=(224, 224))\n",
    "    frames2_tensor = preprocess_frames(frames2, size=(224, 224))\n",
    "    for i in range(len(frames1_tensor)):\n",
    "        f1 = frames1_tensor[i].unsqueeze(0).to(device)\n",
    "        f2 = frames2_tensor[i].unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            score = lpips_model(f1, f2).item()\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "def gif_to_frames(gif_path):\n",
    "    with Image.open(gif_path) as im:\n",
    "        frames = [frame.convert(\"RGB\").copy() for frame in ImageSequence.Iterator(im)]\n",
    "    return frames\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')  \n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * np.log10(PIXEL_MAX / np.sqrt(mse))\n",
    "\n",
    "def compute_ssim(frames1, frames2):\n",
    "    scores = []\n",
    "    for img1, img2 in zip(frames1, frames2):\n",
    "        img1_np = np.array(img1.resize((256, 256))).astype(np.float32)\n",
    "        img2_np = np.array(img2.resize((256, 256))).astype(np.float32)\n",
    "\n",
    "        if img1_np.ndim == 3:\n",
    "            # For RGB images, compute mean SSIM over channels\n",
    "            ssim_val = 0\n",
    "            for c in range(3):\n",
    "                ssim_val += ssim(img1_np[:, :, c], img2_np[:, :, c], data_range=255)\n",
    "            ssim_val /= 3\n",
    "        else:\n",
    "            ssim_val = ssim(img1_np, img2_np, data_range=255)\n",
    "\n",
    "        scores.append(ssim_val)\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f5c22-08a2-4486-9163-2b5fc3fa753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "# Load the motion adapter\n",
    "adapter = MotionAdapter.from_pretrained(\"guoyww/animatediff-motion-adapter-v1-5-2\", torch_dtype=torch.float16)\n",
    "# load SD 1.5 based finetuned model\n",
    "model_id = \"SG161222/Realistic_Vision_V5.1_noVAE\"\n",
    "pipe = AnimateDiffPipeline.from_pretrained(model_id, motion_adapter=adapter, torch_dtype=torch.float16)\n",
    "pipe.scheduler = DDIMScheduler.from_pretrained(model_id, subfolder=\"scheduler\", clip_sample=False, timestep_spacing=\"linspace\", beta_schedule=\"linear\", steps_offset=1)\n",
    "# pipe.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config, timestep_spacing=\"trailing\", beta_schedule=\"linear\")\n",
    "\n",
    "\n",
    "pipe = pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2d28d5-211d-483f-ade4-feb4bedff6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cacher = LightCacher(pipe, 25)\n",
    "cacher.set_params(cache_interval=2, cache_branch_id=0)\n",
    "cacher.enable(Swap=True, Slice=True, Chunk=True)\n",
    "\n",
    "# cacher = FMEWrapper(num_temporal_chunk=9, num_spatial_chunk=2, num_frames=25)\n",
    "# cacher.wrap(pipe)\n",
    "torch.cuda.reset_peak_memory_stats('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ccf6b8-8085-40ac-83c5-addf4d19198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "output = pipe(\n",
    "    prompt=(\n",
    "        \"masterpiece, bestquality, highlydetailed, ultradetailed, sunset, \"\n",
    "        \"orange sky, warm lighting, fishing boats, ocean waves seagulls, \"\n",
    "        \"rippling water, wharf, silhouette, serene atmosphere, dusk, evening glow, \"\n",
    "        \"golden hour, coastal landscape, seaside scenery\"\n",
    "    ),\n",
    "    negative_prompt=\"bad quality, worse quality\",\n",
    "    num_frames=25,\n",
    "    guidance_scale=7.5,\n",
    "    num_inference_steps=50,\n",
    "    generator=torch.Generator(device).manual_seed(42),\n",
    ")\n",
    "print(time() - start_time)\n",
    "\n",
    "frames = output.frames[0]\n",
    "# export_to_gif(frames, \"./generated_videos/AnimateDiff_50step_FME.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27020b3-f1d6-4cc4-aaba-b1adbe29dae8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
