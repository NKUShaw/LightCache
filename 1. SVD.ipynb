{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59d6cc0b-b63f-48ea-a975-16bab68d414a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableVideoDiffusionPipeline, AutoencoderKL\n",
    "from diffusers.utils import load_image, export_to_video\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import Resize, ToTensor, Compose\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import lpips\n",
    "import numpy as np\n",
    "from torchvision.models.video import r3d_18, R3D_18_Weights\n",
    "from scipy import linalg\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from typing import List\n",
    "from LightCache.LightCache import LightCacher\n",
    "from fme import FMEWrapper\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba05019-b9cb-483b-bcc1-33ff7816dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_frames(frames, size=(256, 256)):\n",
    "    transform = Compose([\n",
    "        Resize(size),\n",
    "        ToTensor(),                     # (C, H, W), range [0,1]\n",
    "        lambda x: x * 2 - 1             # normalize to [-1, 1]\n",
    "    ])\n",
    "    return [transform(f) for f in frames]\n",
    "\n",
    "def measure_block_latency(unet):\n",
    "    device = 'cuda'\n",
    "    timings = {}\n",
    "    start_events = {}\n",
    "    end_events = {}\n",
    "\n",
    "    def pre_hook(name):\n",
    "        def inner(module, input):\n",
    "            torch.cuda.synchronize()\n",
    "            evt = torch.cuda.Event(enable_timing=True)\n",
    "            evt.record()\n",
    "            start_events[name] = evt\n",
    "        return inner\n",
    "\n",
    "    def post_hook(name):\n",
    "        def inner(module, input, output):\n",
    "            torch.cuda.synchronize()\n",
    "            evt = torch.cuda.Event(enable_timing=True)\n",
    "            evt.record()\n",
    "            end_events[name] = evt\n",
    "        return inner\n",
    "\n",
    "    handles = []\n",
    "    for name, module in unet.named_modules():\n",
    "        if any(name == f\"{prefix}.{i}\" for prefix in ['down_blocks', 'up_blocks'] for i in range(4)) or name == \"mid_block\":\n",
    "            handles.append(module.register_forward_pre_hook(pre_hook(name)))\n",
    "            handles.append(module.register_forward_hook(post_hook(name)))\n",
    "\n",
    "    def compute_timings():\n",
    "        for name in start_events:\n",
    "            if name in end_events:\n",
    "                elapsed = start_events[name].elapsed_time(end_events[name])  # ms\n",
    "                if name not in timings:\n",
    "                    timings[name] = []\n",
    "                timings[name].append(elapsed)\n",
    "        return timings, handles\n",
    "\n",
    "    return compute_timings\n",
    "\n",
    "\n",
    "\n",
    "def compute_lpips(frames1, frames2):\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "    scores = []\n",
    "    frames1_tensor = preprocess_frames(frames1, size=(224, 224))\n",
    "    frames2_tensor = preprocess_frames(frames2, size=(224, 224))\n",
    "    for i in range(len(frames1_tensor)):\n",
    "        f1 = frames1_tensor[i].unsqueeze(0).to(device)\n",
    "        f2 = frames2_tensor[i].unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            score = lpips_model(f1, f2).item()\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "\n",
    "def read_video_as_pil_frames(video_path: str) -> List[Image.Image]:\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(f\"Failed to open video file: {video_path}\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # OpenCV: BGR â†’ RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(frame_rgb)\n",
    "        frames.append(pil_image)\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def register_memory_hooks(model):\n",
    "    mem_stats = {}\n",
    "\n",
    "    def pre_hook(module, input):\n",
    "        torch.cuda.synchronize()\n",
    "        module._pre_mem = torch.cuda.memory_allocated()\n",
    "\n",
    "    def post_hook(module, input, output):\n",
    "        torch.cuda.synchronize()\n",
    "        post_mem = torch.cuda.memory_allocated()\n",
    "        delta = (post_mem - getattr(module, '_pre_mem', 0)) / 1024 ** 2\n",
    "        name = module._get_name()\n",
    "        if name not in mem_stats:\n",
    "            mem_stats[name] = []\n",
    "        mem_stats[name].append(delta)\n",
    "\n",
    "    handles = []\n",
    "    for name, module in model.named_modules():\n",
    "        if any(x in name for x in ['down_blocks', 'up_blocks', 'mid_block']):\n",
    "            handles.append(module.register_forward_pre_hook(pre_hook))\n",
    "            handles.append(module.register_forward_hook(post_hook))\n",
    "\n",
    "    return mem_stats, handles\n",
    "\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')  \n",
    "    PIXEL_MAX = 255.0\n",
    "    return 20 * np.log10(PIXEL_MAX / np.sqrt(mse))\n",
    "\n",
    "def calculate_ssim(img1, img2):\n",
    "    return ssim(img1, img2, data_range=img2.max() - img2.min(), multichannel=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3708b0-8209-494c-af15-7d28d6ad4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_image(\"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/svd/rocket.png?download=true\")\n",
    "file_name = \"rocket\"\n",
    "image = image.resize((1024, 576))\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "device = 'cuda:3'\n",
    "# pipe = StableVideoDiffusionPipeline.from_pretrained(\"stabilityai/stable-video-diffusion-img2vid-xt\", \n",
    "#                                                     torch_dtype=torch.float16, variant=\"fp16\").to(device)\n",
    "\n",
    "vae = AutoencoderKL.from_pretrained(\"stabilityai/sd-vae-ft-ema\", torch_dtype=torch.float16)\n",
    "pipe = StableVideoDiffusionPipeline.from_pretrained(\"stabilityai/stable-video-diffusion-img2vid-xt\", vae=vae,\n",
    "                                                    torch_dtype=torch.float16, variant=\"fp16\").to(device)\n",
    "\n",
    "\n",
    "generator = torch.Generator(device=device).manual_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0471a505-3cff-44a3-897c-c0a1d62653df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cacher = LightCacher(pipe, 25)\n",
    "# cacher.set_params(cache_interval=8, cache_branch_id=0)\n",
    "# cacher.enable(Swap=True, Slice=True, Chunk=True)\n",
    "\n",
    "# cacher = FMEWrapper(num_temporal_chunk=9, num_spatial_chunk=2, num_frames=25)\n",
    "# cacher.wrap(pipe)\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312d437c-fda5-40cd-be7e-b2dd24b12c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_timings = measure_block_latency(pipe.unet)\n",
    "\n",
    "start_time = time.time()\n",
    "frames = pipe(image, decode_chunk_size=8, generator=generator, num_frames=25).frames[0]\n",
    "print(time.time() - start_time)\n",
    "peak_mem_reserved = torch.cuda.max_memory_reserved(device) / 1024 ** 2  # MB\n",
    "\n",
    "# export_to_video(frames, \"generated_videos/SVD_our.mp4\", fps=7)\n",
    "\n",
    "print(f\"Peak memory reserved: {peak_mem_reserved:.2f} MB\")\n",
    "\n",
    "origin = read_video_as_pil_frames(\"generated_videos/rocket_origin.mp4\")\n",
    "print(compute_lpips(frames, origin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853ee7af-5a4d-4051-8032-d0d93e543ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
